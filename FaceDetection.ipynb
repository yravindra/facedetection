{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uPKGGi_0WNQd3KSpv8zbhlkaNRvgALai",
      "authorship_tag": "ABX9TyPoCY+O5cz8lZFiIz/BIM9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yravindra/facedetection/blob/master/FaceDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsxD_JSMR0Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL.Image\n",
        "import PIL.ImageDraw\n",
        "import dlib\n",
        "import face_recognition\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accessing My Google Drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0CG-KM3TXzU",
        "colab_type": "code",
        "outputId": "dadb6f3f-f96e-4295-8dd1-4db22bd8a684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!pip install face_recognition\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.1)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=d0aa0df10ff3ba1718c43de94009d0e9b40cb44f420d0c8028fd9f0069c3f616\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTsprOF3Ticq",
        "colab_type": "code",
        "outputId": "9dbe044a-f087-45e4-fffc-d74132e323df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#face detection \n",
        "# def loadImages(path):\n",
        "#     '''Put files into lists and return them as one list with all images \n",
        "#      in the folder'''\n",
        "#     image_files = sorted([os.path.join(path, 'train', file)\n",
        "#                           for file in os.listdir(path + \"/train\")\n",
        "#                           if file.endswith('.png')])\n",
        "#     return image_files\n",
        "\n",
        "# imagepath = loadImages()\n",
        "#load the jpg file into numpy array   \n",
        "image = face_recognition.load_image_file(\"/content/sample_data/people.jpg\")\n",
        "#find all the faces in the image \n",
        "face_locations = face_recognition.face_locations(image)\n",
        "# c number of face in the image \n",
        "number_of_faces = len(face_locations)\n",
        "print(\"I found {} face(s) in this photograph.\".format(number_of_faces))\n",
        "\n",
        "#Load the image into a python Image Libraray  object so that we can  draw on top \n",
        "pil_image = PIL.Image.fromarray(image)\n",
        "draw = PIL.ImageDraw.Draw(pil_image)\n",
        "\n",
        "\n",
        "for face_location in face_locations:\n",
        "      # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order\n",
        "      top,right,bottom,left = face_location\n",
        "      print(\"A face is located at pixel location Top:{},Left:{},Bottom:{},Right:{}\".format(top,left,bottom,right))\n",
        "      #Let's Draw a box around  the face \n",
        "      draw.rectangle([left,top,right,bottom],outline=\"red\")\n",
        "\n",
        "#Display the image on screen \n",
        "\n",
        "pil_image.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I found 6 face(s) in this photograph.\n",
            "A face is located at pixel location Top:163,Left:497,Bottom:271,Right:605\n",
            "A face is located at pixel location Top:186,Left:275,Bottom:275,Right:364\n",
            "A face is located at pixel location Top:211,Left:67,Bottom:319,Right:175\n",
            "A face is located at pixel location Top:295,Left:653,Bottom:402,Right:760\n",
            "A face is located at pixel location Top:271,Left:366,Bottom:378,Right:474\n",
            "A face is located at pixel location Top:152,Left:724,Bottom:259,Right:832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swb40OzXV9Fk",
        "colab_type": "code",
        "outputId": "c26f9b15-c080-4d08-91d5-5ecb2d208289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(face_locations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(163, 605, 271, 497), (186, 364, 275, 275), (211, 175, 319, 67), (295, 760, 402, 653), (271, 474, 378, 366), (152, 832, 259, 724)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RAyT3eNVMiM",
        "colab_type": "code",
        "outputId": "19296718-bdfc-4975-ffb4-009e7bc9ffd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "#face land mark recognition  \n",
        "image_land = face_recognition.load_image_file(\"/content/sample_data/people.jpg\")\n",
        "\n",
        "#find the all facial feature in all the faces in the images \n",
        "face_landmarks_list = face_recognition.face_landmarks(image_land)\n",
        "\n",
        "#finding the number of the images  in the list \n",
        "number_of_faces_landmark = len(face_landmarks_list)\n",
        "\n",
        "print(\"I found {} face(s) in this photograph.\".format(number_of_faces_landmark))\n",
        "#load the image into python image file libarary obeject so that  we can draw on the top \n",
        "pil_image = PIL.Image.fromarray(image_land)\n",
        "\n",
        "#Create a PIL drawing object to be able to draw lines later \n",
        "draw = PIL.ImageDraw.Draw(pil_image)\n",
        "#loop over each facial feature ()\n",
        "for face_landmarks in face_landmarks_list:\n",
        "  for name,list_of_points in face_landmarks.items():\n",
        "    print(\"The {} in this face has the following points:{}\".format(name,list_of_points))\n",
        "    draw.line(list_of_points,fill=\"red\",width=2)\n",
        "\n",
        "\n",
        "# Display one image\n",
        "def display_one(a, title1 = \"Original\"):\n",
        "    plt.imshow(a), plt.title(title1)\n",
        "    plt.show()\n",
        "\n",
        "display_one(pil_image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I found 6 face(s) in this photograph.\n",
            "The chin in this face has the following points:[(497, 193), (498, 206), (499, 219), (500, 232), (504, 244), (512, 255), (521, 264), (532, 271), (544, 274), (557, 272), (569, 266), (579, 258), (588, 247), (593, 234), (596, 221), (597, 208), (598, 194)]\n",
            "The left_eyebrow in this face has the following points:[(508, 186), (514, 182), (520, 179), (528, 179), (536, 181)]\n",
            "The right_eyebrow in this face has the following points:[(558, 180), (566, 179), (574, 179), (582, 180), (588, 186)]\n",
            "The nose_bridge in this face has the following points:[(547, 191), (546, 200), (546, 208), (545, 217)]\n",
            "The nose_tip in this face has the following points:[(536, 221), (541, 223), (546, 225), (551, 223), (556, 221)]\n",
            "The left_eye in this face has the following points:[(517, 193), (522, 190), (528, 190), (533, 193), (527, 194), (522, 194)]\n",
            "The right_eye in this face has the following points:[(562, 193), (567, 190), (573, 190), (578, 193), (573, 194), (567, 194)]\n",
            "The top_lip in this face has the following points:[(526, 236), (533, 234), (540, 233), (546, 235), (551, 234), (558, 235), (565, 237), (563, 237), (551, 236), (545, 236), (540, 235), (528, 236)]\n",
            "The bottom_lip in this face has the following points:[(565, 237), (558, 243), (550, 246), (545, 246), (539, 245), (532, 242), (526, 236), (528, 236), (539, 240), (545, 241), (551, 241), (563, 237)]\n",
            "The chin in this face has the following points:[(275, 203), (276, 214), (277, 225), (278, 237), (282, 247), (288, 257), (296, 265), (304, 272), (315, 275), (326, 274), (335, 268), (342, 260), (347, 250), (351, 241), (354, 230), (355, 219), (356, 208)]\n",
            "The left_eyebrow in this face has the following points:[(284, 196), (290, 192), (297, 193), (303, 195), (310, 199)]\n",
            "The right_eyebrow in this face has the following points:[(327, 199), (334, 196), (341, 194), (348, 195), (352, 200)]\n",
            "The nose_bridge in this face has the following points:[(319, 207), (318, 215), (318, 223), (318, 230)]\n",
            "The nose_tip in this face has the following points:[(307, 232), (312, 234), (318, 236), (323, 235), (328, 234)]\n",
            "The left_eye in this face has the following points:[(291, 206), (296, 203), (302, 204), (306, 209), (301, 209), (295, 209)]\n",
            "The right_eye in this face has the following points:[(330, 210), (335, 207), (341, 206), (345, 209), (341, 211), (335, 211)]\n",
            "The top_lip in this face has the following points:[(296, 242), (304, 240), (311, 240), (317, 242), (323, 241), (330, 242), (336, 245), (334, 245), (322, 245), (317, 245), (311, 244), (298, 243)]\n",
            "The bottom_lip in this face has the following points:[(336, 245), (330, 255), (322, 259), (316, 259), (310, 258), (302, 253), (296, 242), (298, 243), (311, 252), (317, 253), (322, 252), (334, 245)]\n",
            "The chin in this face has the following points:[(65, 230), (65, 244), (65, 258), (65, 272), (68, 286), (74, 298), (83, 309), (94, 318), (107, 323), (122, 323), (136, 318), (149, 310), (159, 299), (166, 286), (170, 271), (173, 257), (175, 242)]\n",
            "The left_eyebrow in this face has the following points:[(76, 223), (84, 218), (94, 218), (104, 219), (113, 224)]\n",
            "The right_eyebrow in this face has the following points:[(129, 226), (139, 224), (149, 224), (159, 227), (166, 234)]\n",
            "The nose_bridge in this face has the following points:[(120, 235), (119, 245), (117, 254), (116, 265)]\n",
            "The nose_tip in this face has the following points:[(103, 268), (109, 270), (115, 273), (122, 272), (129, 271)]\n",
            "The left_eye in this face has the following points:[(88, 231), (94, 229), (100, 230), (105, 235), (99, 235), (93, 233)]\n",
            "The right_eye in this face has the following points:[(135, 239), (141, 235), (147, 236), (153, 240), (147, 240), (140, 240)]\n",
            "The top_lip in this face has the following points:[(89, 278), (98, 279), (107, 281), (114, 283), (122, 283), (131, 284), (140, 285), (137, 286), (121, 285), (114, 285), (106, 283), (92, 280)]\n",
            "The bottom_lip in this face has the following points:[(140, 285), (130, 297), (119, 301), (112, 301), (104, 299), (95, 292), (89, 278), (92, 280), (105, 291), (113, 294), (120, 294), (137, 286)]\n",
            "The chin in this face has the following points:[(655, 327), (654, 341), (654, 355), (657, 369), (664, 381), (674, 393), (684, 403), (696, 411), (710, 414), (723, 411), (735, 403), (746, 393), (754, 381), (760, 367), (763, 353), (764, 338), (763, 325)]\n",
            "The left_eyebrow in this face has the following points:[(665, 311), (672, 305), (681, 304), (690, 307), (697, 311)]\n",
            "The right_eyebrow in this face has the following points:[(718, 310), (727, 306), (736, 303), (746, 305), (753, 311)]\n",
            "The nose_bridge in this face has the following points:[(708, 321), (709, 331), (709, 342), (709, 352)]\n",
            "The nose_tip in this face has the following points:[(695, 355), (702, 357), (709, 360), (716, 358), (722, 355)]\n",
            "The left_eye in this face has the following points:[(673, 320), (680, 318), (687, 319), (693, 324), (686, 323), (680, 322)]\n",
            "The right_eye in this face has the following points:[(723, 323), (729, 318), (736, 317), (742, 319), (737, 321), (730, 322)]\n",
            "The top_lip in this face has the following points:[(680, 367), (689, 364), (699, 364), (708, 366), (716, 364), (727, 364), (737, 366), (734, 367), (716, 368), (708, 369), (699, 368), (682, 367)]\n",
            "The bottom_lip in this face has the following points:[(737, 366), (728, 379), (717, 385), (708, 386), (699, 385), (689, 379), (680, 367), (682, 367), (699, 379), (708, 379), (717, 378), (734, 367)]\n",
            "The chin in this face has the following points:[(362, 296), (362, 310), (364, 324), (366, 336), (371, 349), (379, 361), (389, 371), (400, 379), (412, 382), (424, 380), (435, 371), (444, 361), (452, 349), (456, 337), (458, 324), (460, 312), (461, 300)]\n",
            "The left_eyebrow in this face has the following points:[(376, 292), (383, 288), (392, 286), (401, 287), (409, 292)]\n",
            "The right_eyebrow in this face has the following points:[(424, 294), (432, 292), (440, 291), (448, 293), (454, 297)]\n",
            "The nose_bridge in this face has the following points:[(417, 299), (417, 308), (417, 318), (417, 328)]\n",
            "The nose_tip in this face has the following points:[(406, 330), (411, 333), (417, 335), (422, 333), (426, 331)]\n",
            "The left_eye in this face has the following points:[(388, 298), (393, 295), (400, 294), (405, 299), (399, 299), (393, 299)]\n",
            "The right_eye in this face has the following points:[(426, 300), (432, 296), (438, 296), (444, 299), (438, 301), (432, 300)]\n",
            "The top_lip in this face has the following points:[(388, 339), (398, 339), (407, 340), (414, 342), (420, 340), (428, 340), (437, 341), (433, 342), (421, 343), (414, 344), (407, 343), (391, 340)]\n",
            "The bottom_lip in this face has the following points:[(437, 341), (428, 352), (420, 357), (414, 357), (406, 356), (396, 351), (388, 339), (391, 340), (406, 351), (414, 352), (420, 351), (433, 342)]\n",
            "The chin in this face has the following points:[(744, 188), (742, 199), (741, 210), (741, 222), (745, 234), (751, 244), (759, 254), (766, 263), (778, 266), (791, 265), (802, 259), (814, 251), (823, 242), (830, 230), (833, 217), (833, 204), (834, 191)]\n",
            "The left_eyebrow in this face has the following points:[(747, 176), (750, 170), (757, 167), (765, 168), (772, 171)]\n",
            "The right_eyebrow in this face has the following points:[(785, 171), (795, 169), (804, 169), (813, 173), (819, 179)]\n",
            "The nose_bridge in this face has the following points:[(778, 182), (777, 189), (776, 195), (775, 203)]\n",
            "The nose_tip in this face has the following points:[(764, 209), (770, 211), (776, 213), (783, 211), (789, 210)]\n",
            "The left_eye in this face has the following points:[(753, 183), (758, 180), (764, 180), (769, 184), (764, 185), (758, 185)]\n",
            "The right_eye in this face has the following points:[(792, 185), (798, 181), (804, 181), (809, 185), (804, 187), (798, 187)]\n",
            "The top_lip in this face has the following points:[(755, 226), (761, 221), (770, 220), (776, 222), (783, 221), (793, 223), (802, 228), (799, 228), (783, 224), (776, 225), (769, 224), (758, 226)]\n",
            "The bottom_lip in this face has the following points:[(802, 228), (793, 238), (783, 242), (775, 242), (769, 241), (761, 236), (755, 226), (758, 226), (769, 235), (776, 236), (783, 236), (799, 228)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4QHthNhffeH",
        "colab_type": "code",
        "outputId": "86739bc6-5249-4d7d-8eca-d5ffaea9eaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "#face encoding model code \n",
        "image_encoding = face_recognition.load_image_file(\"/content/sample_data/person2.png\")\n",
        "#genrating the face encodings\n",
        "face_encoding = face_recognition.face_encodings(image_encoding)\n",
        "\n",
        "if(len(face_encoding)==0):\n",
        "  print(\"you dont have any person similar to this person\")\n",
        "else:\n",
        "  #grab the first face encoding \n",
        "  first_face_encoding = face_encoding[0]\n",
        "  #print the result\n",
        "  print(first_face_encoding)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-3.26377712e-03  7.94689804e-02  5.80458120e-02 -5.79938404e-02\n",
            " -1.72667399e-01  3.28100137e-02 -5.06189167e-02 -1.42689556e-01\n",
            "  1.70358017e-01 -6.29137605e-02  3.23670328e-01 -1.02984853e-01\n",
            " -2.09157392e-01 -4.62254435e-02  1.26105696e-02  7.87239894e-02\n",
            " -1.49928793e-01 -1.02184355e-01 -6.17962796e-03 -8.67726132e-02\n",
            "  1.08045071e-01  1.13098405e-01  6.50096685e-04 -9.99948010e-03\n",
            " -1.32999048e-01 -3.02664012e-01 -1.04714386e-01 -1.32422984e-01\n",
            "  1.70418352e-01 -7.06224293e-02  3.07826605e-02  8.15370902e-02\n",
            " -1.59978628e-01 -8.24953690e-02  3.48323882e-02 -3.77645418e-02\n",
            " -1.09672010e-01 -7.21320137e-02  1.84596673e-01 -5.51346131e-03\n",
            " -1.81504369e-01 -7.22384453e-02  2.05350816e-02  1.93359584e-01\n",
            "  9.02286917e-02  2.95058563e-02  5.18783405e-02 -7.94474259e-02\n",
            "  4.31035087e-02 -2.27743745e-01  4.11492661e-02  1.76978722e-01\n",
            "  1.02088094e-01 -1.02072954e-06  1.14917941e-01 -1.59087002e-01\n",
            " -7.35853147e-03  1.61077991e-01 -1.67199805e-01  1.50417745e-01\n",
            "  1.24399066e-01 -9.55460072e-02 -2.40305830e-02 -5.82996607e-02\n",
            "  2.07755700e-01  4.17512581e-02 -3.71698886e-02 -1.66907638e-01\n",
            "  1.72855377e-01 -6.01954497e-02 -1.51523322e-01  1.64805174e-01\n",
            " -1.38672248e-01 -1.61753237e-01 -2.92982996e-01 -3.34758423e-02\n",
            "  5.02061725e-01  1.53601300e-02 -1.69729903e-01  4.73386720e-02\n",
            " -2.47970372e-02  4.80945781e-03  1.41677424e-01  4.41400483e-02\n",
            " -2.28878595e-02 -9.42441970e-02 -1.34051204e-01 -2.17790529e-02\n",
            "  1.88411266e-01 -1.02903984e-01 -2.99338773e-02  2.03956932e-01\n",
            " -3.77562642e-02  7.76598155e-02  4.15927991e-02  4.13546525e-02\n",
            " -5.00302315e-02 -1.04583614e-02 -3.96940298e-02 -2.75193416e-02\n",
            "  4.25439216e-02 -5.82264885e-02 -4.05390151e-02  1.49498329e-01\n",
            " -1.52286112e-01  1.47759289e-01  7.65910745e-03 -1.06924847e-02\n",
            " -3.29655083e-03 -6.42370209e-02 -3.41329724e-02  8.08311626e-03\n",
            "  1.91326857e-01 -2.92265296e-01  1.50710955e-01  1.25357017e-01\n",
            "  1.85787361e-02  1.32097274e-01  2.10881121e-02  3.24604064e-02\n",
            " -2.33909097e-02 -6.76686466e-02 -2.62509674e-01 -8.70959982e-02\n",
            "  3.18779424e-03 -8.75215009e-02 -7.72160590e-02  1.30109079e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moeuhMW_mBU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "38408372-2cfd-49fc-8dd1-56d78fd0225b"
      },
      "source": [
        "#face recognition system  \n",
        "#load the images \n",
        "image_of_person1 = face_recognition.load_image_file(\"/content/sample_data/person_1.jpg\")\n",
        "image_of_person2 = face_recognition.load_image_file(\"/content/sample_data/person_2.jpg\")\n",
        "image_of_person3 = face_recognition.load_image_file(\"/content/sample_data/person_3.jpg\")\n",
        "\n",
        "#get the face encoding of each person .This can if no one is found \n",
        "person_1_face_encoding = face_recognition.face_encodings(image_of_person1)[0]\n",
        "person_2_face_encoding = face_recognition.face_encodings(image_of_person2)[0]\n",
        "person_3_face_encoding = face_recognition.face_encodings(image_of_person3)[0]\n",
        "\n",
        "\n",
        "#create the list of all the know face of encoding \n",
        "known_face_encodings = [\n",
        "                       person_1_face_encoding,\n",
        "                       person_2_face_encoding,\n",
        "                       person_3_face_encoding\n",
        "]\n",
        "\n",
        "#load the image we want to check \n",
        "unknown_image = face_recognition.load_image_file(\"/content/sample_data/unknown_4.jpg\")\n",
        "unknown_image_encodings = face_recognition.face_encodings(unknown_image)\n",
        "print(\"ecodnigs\",person_1_face_encoding)\n",
        "#There are the might be more than one person in the photo ,so we neeed to loop over  each face we found.\n",
        "for unknown_face_encoding in unknown_image_encodings:\n",
        "  result = face_recognition.compare_faces(known_face_encodings,unknown_face_encoding,tolerance=0.6)\n",
        "  name = \"unkonwn\"\n",
        "  if result[0]:\n",
        "    name =\"Person1\"\n",
        "  elif result[1]:\n",
        "    name = \"Person2\"\n",
        "  elif result[3]:\n",
        "    name = \"Person3\"\n",
        "print(f\"Found the {name} in the photo!\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ecodnigs [-1.21599324e-01  2.58645210e-02  1.03641808e-01 -1.03552707e-01\n",
            " -1.10634521e-01 -3.85044441e-02  3.56080011e-04 -6.07901327e-02\n",
            "  1.96002692e-01 -1.73807323e-01  1.98144346e-01 -5.09199128e-02\n",
            " -1.45644441e-01  3.24478112e-02 -5.55986799e-02  2.46766880e-01\n",
            " -1.45866483e-01 -1.36574149e-01 -6.38571009e-02 -1.23729445e-01\n",
            " -3.76427770e-02 -1.00629907e-02  3.08628865e-02  1.77302659e-01\n",
            " -9.24702212e-02 -3.36816937e-01 -7.46231824e-02 -8.50740895e-02\n",
            "  4.97743767e-03 -9.17778164e-02 -9.64255072e-03  1.34384677e-01\n",
            " -2.53169149e-01  2.72017773e-02 -3.80300917e-02  1.18446432e-01\n",
            "  1.84719097e-02 -7.01441467e-02  8.94314498e-02  4.49470393e-02\n",
            " -2.42769822e-01 -6.88361600e-02  2.13776678e-02  2.71462679e-01\n",
            "  2.18737602e-01 -1.12367012e-01 -2.34918483e-03 -4.16985638e-02\n",
            "  1.35063045e-02 -2.06458643e-01 -1.78441536e-02  4.73509952e-02\n",
            "  4.71367314e-02  5.64071536e-02 -3.63615453e-02 -1.11835212e-01\n",
            "  5.24802953e-02  7.98514485e-02 -1.01878002e-01 -2.89066918e-02\n",
            "  3.94381955e-03 -7.79650882e-02 -4.43467796e-02 -3.19837034e-02\n",
            "  3.10580015e-01  1.27640814e-01 -1.29377812e-01 -1.31537586e-01\n",
            "  2.16277018e-01 -1.66079178e-01 -1.44928340e-02  4.32951078e-02\n",
            " -1.24379046e-01 -1.25214666e-01 -2.85136878e-01  4.88032959e-03\n",
            "  4.45413440e-01  1.10655382e-01 -2.18656778e-01  8.93277675e-02\n",
            " -1.73228055e-01  8.43518972e-03 -3.00317537e-03  1.85837194e-01\n",
            " -7.05161765e-02  1.34614229e-01 -4.30733711e-02  6.15408532e-02\n",
            "  1.89571843e-01  1.09126139e-02 -3.05136833e-02  2.51588285e-01\n",
            " -4.70192544e-03 -3.31569975e-03  8.19883272e-02  1.14959776e-02\n",
            " -4.22398299e-02 -4.83034924e-02 -2.02634558e-01 -8.97312090e-02\n",
            " -6.81549385e-02 -7.37844855e-02 -7.40826279e-02  1.15265302e-01\n",
            " -2.85762399e-01  2.14100301e-01  5.05407751e-02 -3.14277634e-02\n",
            "  2.03205142e-02  1.39065608e-01 -6.84656352e-02 -1.02380045e-01\n",
            "  1.67825297e-01 -2.23027527e-01  8.89012367e-02  2.24712208e-01\n",
            "  1.13217264e-01  1.67999268e-01  7.37358183e-02  1.02692187e-01\n",
            " -1.99675169e-02 -5.51137850e-02 -1.09105960e-01  5.14431521e-02\n",
            "  8.25397894e-02 -1.19850568e-01  1.96863469e-02  6.31118864e-02]\n",
            "Found the Person2 in the photo!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs5-SurZ06jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85c42839-6bf1-4742-b2f9-6d357608c6c8"
      },
      "source": [
        "#image recognizaation  tunning  \n",
        "#if the image size is small its pixel quality is not too good then we are tunning feature \n",
        "#load the know Images \n",
        "image_of_person1 =  face_recognition.load_image_file(\"/content/sample_data/person_1.jpg\")\n",
        "image_of_person2 = face_recognition.load_image_file(\"/content/sample_data/person_2.jpg\")\n",
        "image_of_person3 = face_recognition.load_image_file(\"/content/sample_data/person_3.jpg\")\n",
        "\n",
        "#get the face of encoding of the each person ,This can fail if no one is found in the photo\n",
        "person_1_face_encoding  = face_recognition.face_encodings(image_of_person1)[0]\n",
        "person_2_face_encoding = face_recognition.face_encodings(image_of_person2)[0]\n",
        "person_3_face_encoding = face_recognition.face_encodings(image_of_person3)[0]\n",
        "\n",
        "#create the list of know face encoding \n",
        "known_face_encodings = [\n",
        "                        person_1_face_encoding,\n",
        "                        person_2_face_encoding,\n",
        "                        person_3_face_encoding\n",
        "                        \n",
        "]\n",
        "\n",
        "#load the images we want to check \n",
        "unknown_face_encoding = face_recognition.load_image_file(\"/content/sample_data/unknown_8.jpg\")\n",
        "\n",
        "#Get face encodings for any people in the picture \n",
        "face_location = face_recognition.face_locations(unknown_image,number_of_times_to_upsample=2)\n",
        "unknown_face_encodings = face_recognition.face_encodings(unknown_image,known_face_locations=face_location)\n",
        "\n",
        "#There might be more than one person in the photo, so we need to loop over each face we found \n",
        "for unknown_face_encoding in unknown_face_encodings:\n",
        "  results  = face_recognition.compare_faces(known_face_encodings,unknown_face_encoding,tolerance=2)\n",
        "  name = \"unknown\"\n",
        "\n",
        "  if results[0]:\n",
        "    name =\"Person1\"\n",
        "  elif results[0]:\n",
        "    name = \"Person2\"\n",
        "  elif results[0]:\n",
        "    name = \"Preson3\"\n",
        "\n",
        "  print(f\"Found  {name} in the Phtoto!\")\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found  Person1 in the Phtoto!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co-uSkqoIRMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}